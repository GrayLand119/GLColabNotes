{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTEzoMx6CasV"
   },
   "source": [
    "#### Copyright 2018 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "IhmPj1VVCfWb",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHK6DyunSbs4"
   },
   "source": [
    "# Cat vs. Dog Image Classification\n",
    "## Exercise 3: Feature Extraction and Fine-Tuning\n",
    "**_Estimated completion time: 30 minutes_**\n",
    "\n",
    "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
    "\n",
    "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dI5rmt4UBwXs"
   },
   "source": [
    "## Feature Extraction Using a Pretrained Model\n",
    "\n",
    "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
    "\n",
    "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
    "\n",
    "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
    "\n",
    "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0l7PfIfvGs2B",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "6566930a-6a19-4633-8e62-4164506bfc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v1.version' from '/usr/local/lib/python2.7/dist-packages/tensorflow/_api/v1/version/__init__.pyc'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print tf.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaXLMtYiF0t9"
   },
   "source": [
    "Now let's download the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "KMrbllgAFipZ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    },
    "outputId": "c1168603-89dc-41b9-b56f-1f136c0f9116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-09 03:38:10--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 2a00:1450:4013:c05::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  26.5MB/s    in 3.2s    \n",
      "\n",
      "2019-09-09 03:38:14 (26.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "UnRiGBfOF8rq",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
    "pre_trained_model.load_weights(local_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcYZPBS3bTAj"
   },
   "source": [
    "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFxrqTuJee5m"
   },
   "source": [
    "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "a38rB3lyedcB",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1pYZQPUQdi6p",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "outputId": "d4ae0bf7-0437-4348-da9f-ff5e4fa823b6",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGBGDiOAepnO"
   },
   "source": [
    "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code",
    "id": "Cj4rXshqbQlS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "5135b0fa-860e-4cca-a09a-22c70e1325d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape: (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print 'last layer output shape:', last_layer.output_shape\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxHk6XQLeUWh"
   },
   "source": [
    "Now let's stick a fully connected classifier on top of `last_output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88.0
    },
    "outputId": "84c85f96-d059-4265-9895-e2ebc78dd769"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 05:20:16.288450 139749169833856 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Configure and compile the model\n",
    "model = Model(pre_trained_model.input, x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6ECjowwV5Ug"
   },
   "source": [
    "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cl-IqOTjZVw_"
   },
   "source": [
    "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    },
    "outputId": "cd53b6ed-f363-4dc9-f374-ca6cf1c720e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-09 05:20:29--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 2a00:1450:4013:c05::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
      "\n",
      "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  50.3MB/s    in 1.3s    \n",
      "\n",
      "2019-09-09 05:20:31 (50.3 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
    "   /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code",
    "id": "Fl9XXARuV_eg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "bfc19c52-c2a0-458c-fb85-7aeac967d46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEC1AL7iVRLz"
   },
   "source": [
    "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85.0
    },
    "outputId": "1fff20c2-541b-4467-ae81-ecaf22b2a0b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 - 23s - loss: 0.4896 - acc: 0.7750 - val_loss: 0.2798 - val_acc: 0.9080\n",
      "Epoch 2/2\n",
      "100/100 - 17s - loss: 0.3737 - acc: 0.8355 - val_loss: 0.3318 - val_acc: 0.9190\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=2,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRjyAkE62aOG"
   },
   "source": [
    "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tt15y6IS2pBo"
   },
   "source": [
    "## Further Improving Accuracy with Fine-Tuning\n",
    "\n",
    "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
    "\n",
    "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
    "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
    "\n",
    "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "_l_J4S0Z2rgg",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "unfreeze = False\n",
    "\n",
    "# Unfreeze all models after \"mixed6\"\n",
    "for layer in pre_trained_model.layers:\n",
    "  if unfreeze:\n",
    "    layer.trainable = True\n",
    "  if layer.name == 'mixed6':\n",
    "    unfreeze = True\n",
    "\n",
    "# As an optimizer, here we will use SGD \n",
    "# with a very low learning rate (0.00001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(\n",
    "                  lr=0.00001, \n",
    "                  momentum=0.9),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE37ARlqY9da"
   },
   "source": [
    "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 test images. (This may take 15-20 minutes to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code",
    "id": "o_GgDGG4Y_hJ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "outputId": "4370bec7-67cf-4ace-938d-71c8afa57b0c",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 - 21s - loss: 0.3130 - acc: 0.8615 - val_loss: 0.3488 - val_acc: 0.9150\n",
      "Epoch 2/50\n",
      "100/100 - 17s - loss: 0.2948 - acc: 0.8710 - val_loss: 0.3552 - val_acc: 0.9180\n",
      "Epoch 3/50\n",
      "100/100 - 17s - loss: 0.2903 - acc: 0.8735 - val_loss: 0.3565 - val_acc: 0.9190\n",
      "Epoch 4/50\n",
      "100/100 - 17s - loss: 0.2900 - acc: 0.8660 - val_loss: 0.3563 - val_acc: 0.9190\n",
      "Epoch 5/50\n",
      "100/100 - 17s - loss: 0.2906 - acc: 0.8700 - val_loss: 0.3541 - val_acc: 0.9190\n",
      "Epoch 6/50\n",
      "100/100 - 17s - loss: 0.2965 - acc: 0.8640 - val_loss: 0.3503 - val_acc: 0.9210\n",
      "Epoch 7/50\n",
      "100/100 - 17s - loss: 0.2811 - acc: 0.8725 - val_loss: 0.3521 - val_acc: 0.9210\n",
      "Epoch 8/50\n",
      "100/100 - 17s - loss: 0.2866 - acc: 0.8820 - val_loss: 0.3458 - val_acc: 0.9220\n",
      "Epoch 9/50\n",
      "100/100 - 17s - loss: 0.2769 - acc: 0.8700 - val_loss: 0.3416 - val_acc: 0.9220\n",
      "Epoch 10/50\n",
      "100/100 - 17s - loss: 0.2685 - acc: 0.8800 - val_loss: 0.3407 - val_acc: 0.9230\n",
      "Epoch 11/50\n",
      "100/100 - 17s - loss: 0.2840 - acc: 0.8720 - val_loss: 0.3431 - val_acc: 0.9210\n",
      "Epoch 12/50\n",
      "100/100 - 17s - loss: 0.2743 - acc: 0.8725 - val_loss: 0.3387 - val_acc: 0.9230\n",
      "Epoch 13/50\n",
      "100/100 - 17s - loss: 0.2829 - acc: 0.8740 - val_loss: 0.3297 - val_acc: 0.9230\n",
      "Epoch 14/50\n",
      "100/100 - 17s - loss: 0.2817 - acc: 0.8865 - val_loss: 0.3273 - val_acc: 0.9250\n",
      "Epoch 15/50\n",
      "100/100 - 17s - loss: 0.2709 - acc: 0.8810 - val_loss: 0.3306 - val_acc: 0.9230\n",
      "Epoch 16/50\n",
      "100/100 - 17s - loss: 0.2913 - acc: 0.8770 - val_loss: 0.3268 - val_acc: 0.9250\n",
      "Epoch 17/50\n",
      "100/100 - 17s - loss: 0.2971 - acc: 0.8695 - val_loss: 0.3241 - val_acc: 0.9250\n",
      "Epoch 18/50\n",
      "100/100 - 17s - loss: 0.2959 - acc: 0.8640 - val_loss: 0.3213 - val_acc: 0.9260\n",
      "Epoch 19/50\n",
      "100/100 - 17s - loss: 0.2716 - acc: 0.8810 - val_loss: 0.3196 - val_acc: 0.9260\n",
      "Epoch 20/50\n",
      "100/100 - 17s - loss: 0.2826 - acc: 0.8785 - val_loss: 0.3114 - val_acc: 0.9280\n",
      "Epoch 21/50\n",
      "100/100 - 17s - loss: 0.2837 - acc: 0.8770 - val_loss: 0.3166 - val_acc: 0.9270\n",
      "Epoch 22/50\n",
      "100/100 - 17s - loss: 0.2810 - acc: 0.8770 - val_loss: 0.3099 - val_acc: 0.9280\n",
      "Epoch 23/50\n",
      "100/100 - 17s - loss: 0.2686 - acc: 0.8790 - val_loss: 0.3105 - val_acc: 0.9290\n",
      "Epoch 24/50\n",
      "100/100 - 17s - loss: 0.2803 - acc: 0.8675 - val_loss: 0.3056 - val_acc: 0.9300\n",
      "Epoch 25/50\n",
      "100/100 - 16s - loss: 0.2816 - acc: 0.8780 - val_loss: 0.3076 - val_acc: 0.9290\n",
      "Epoch 26/50\n",
      "100/100 - 17s - loss: 0.2770 - acc: 0.8755 - val_loss: 0.2996 - val_acc: 0.9300\n",
      "Epoch 27/50\n",
      "100/100 - 16s - loss: 0.2699 - acc: 0.8735 - val_loss: 0.2983 - val_acc: 0.9300\n",
      "Epoch 28/50\n",
      "100/100 - 17s - loss: 0.2674 - acc: 0.8775 - val_loss: 0.2943 - val_acc: 0.9300\n",
      "Epoch 29/50\n",
      "100/100 - 17s - loss: 0.2600 - acc: 0.8885 - val_loss: 0.2921 - val_acc: 0.9300\n",
      "Epoch 30/50\n",
      "100/100 - 17s - loss: 0.2556 - acc: 0.8890 - val_loss: 0.2891 - val_acc: 0.9300\n",
      "Epoch 31/50\n",
      "100/100 - 17s - loss: 0.2673 - acc: 0.8815 - val_loss: 0.2934 - val_acc: 0.9310\n",
      "Epoch 32/50\n",
      "100/100 - 17s - loss: 0.2657 - acc: 0.8845 - val_loss: 0.2957 - val_acc: 0.9300\n",
      "Epoch 33/50\n",
      "100/100 - 17s - loss: 0.2726 - acc: 0.8740 - val_loss: 0.2939 - val_acc: 0.9300\n",
      "Epoch 34/50\n",
      "100/100 - 17s - loss: 0.2639 - acc: 0.8880 - val_loss: 0.2957 - val_acc: 0.9300\n",
      "Epoch 35/50\n",
      "100/100 - 17s - loss: 0.2834 - acc: 0.8785 - val_loss: 0.2912 - val_acc: 0.9300\n",
      "Epoch 36/50\n",
      "100/100 - 16s - loss: 0.2626 - acc: 0.8865 - val_loss: 0.2902 - val_acc: 0.9300\n",
      "Epoch 37/50\n",
      "100/100 - 17s - loss: 0.2709 - acc: 0.8785 - val_loss: 0.2893 - val_acc: 0.9300\n",
      "Epoch 38/50\n",
      "100/100 - 17s - loss: 0.2723 - acc: 0.8820 - val_loss: 0.2850 - val_acc: 0.9300\n",
      "Epoch 39/50\n",
      "100/100 - 17s - loss: 0.2551 - acc: 0.8955 - val_loss: 0.2837 - val_acc: 0.9310\n",
      "Epoch 40/50\n",
      "100/100 - 17s - loss: 0.2670 - acc: 0.8865 - val_loss: 0.2847 - val_acc: 0.9300\n",
      "Epoch 41/50\n",
      "100/100 - 17s - loss: 0.2832 - acc: 0.8730 - val_loss: 0.2817 - val_acc: 0.9320\n",
      "Epoch 42/50\n",
      "100/100 - 17s - loss: 0.2692 - acc: 0.8780 - val_loss: 0.2821 - val_acc: 0.9310\n",
      "Epoch 43/50\n",
      "100/100 - 16s - loss: 0.2752 - acc: 0.8785 - val_loss: 0.2759 - val_acc: 0.9330\n",
      "Epoch 44/50\n",
      "100/100 - 16s - loss: 0.2746 - acc: 0.8825 - val_loss: 0.2734 - val_acc: 0.9340\n",
      "Epoch 45/50\n",
      "100/100 - 17s - loss: 0.2704 - acc: 0.8730 - val_loss: 0.2768 - val_acc: 0.9340\n",
      "Epoch 46/50\n",
      "100/100 - 16s - loss: 0.2634 - acc: 0.8830 - val_loss: 0.2734 - val_acc: 0.9350\n",
      "Epoch 47/50\n",
      "100/100 - 17s - loss: 0.2731 - acc: 0.8785 - val_loss: 0.2697 - val_acc: 0.9350\n",
      "Epoch 48/50\n",
      "100/100 - 17s - loss: 0.2769 - acc: 0.8740 - val_loss: 0.2667 - val_acc: 0.9360\n",
      "Epoch 49/50\n",
      "100/100 - 17s - loss: 0.2831 - acc: 0.8745 - val_loss: 0.2662 - val_acc: 0.9370\n",
      "Epoch 50/50\n",
      "100/100 - 17s - loss: 0.2527 - acc: 0.8895 - val_loss: 0.2702 - val_acc: 0.9350\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EPGn58ofwq5"
   },
   "source": [
    "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
    "\n",
    "Let's plot the training and validation loss and accuracy to show it conclusively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code",
    "id": "1FtxcKjJfxL9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562.0
    },
    "outputId": "f1ec9461-3ee7-4d46-db03-7b61c3d740fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Training and validation loss')"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+iGEUCKR9EMIoUT+Bod1OrPmhseGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAV9Y4zxkP8D6U3/6B4HF38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-fUIeizakjE"
   },
   "source": [
    "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_ANwJCnx7w-"
   },
   "source": [
    "## Clean Up\n",
    "\n",
    "Run the following cell to terminate the kernel and free memory resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "-hUmyohAyBzh",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image_classification_part3.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [
    "jTEzoMx6CasV"
   ]
  },
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
